{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPaX/1AHExulmFmNuvyFfAA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xTyBFOL3Rm3","executionInfo":{"status":"ok","timestamp":1768979126777,"user_tz":-330,"elapsed":13394,"user":{"displayName":"Deshna Doshi","userId":"11987811234054001680"}},"outputId":"f48ef9fe-e3e6-495a-e5ed-b2ca818f5d81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"]}],"source":["#training bert for email sentiment analysis\n","!pip install transformers torch scikit-learn pandas openpyxl"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","\n","# Load dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/emails.csv\")\n","\n","# Check size\n","print(df.shape)\n","\n","df = df[['message']]\n","\n","df_sample = df.sample(n=20000, random_state=42)\n","\n","df_sample['original_email'] = df_sample['message']\n","\n","df_sample = df_sample.reset_index(drop=True)\n","\n","#Extract email body\n","def extract_body(email):\n","    if isinstance(email, str):\n","        parts = email.split(\"\\n\\n\", 1)\n","        if len(parts) > 1:\n","            return parts[1]\n","    return email\n","df_sample['email_body'] = df_sample['original_email'].apply(extract_body)\n","\n","#cleaning text\n","import re\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r\"http\\S+\", \"\", text)        # remove URLs\n","    text = re.sub(r\"\\n\", \" \", text)            # remove newlines\n","    text = re.sub(r\"[^a-z\\s]\", \"\", text)       # remove symbols\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","df_sample['clean_email'] = df_sample['email_body'].apply(clean_text)\n","\n","#removing empty rows\n","df_sample = df_sample[df_sample['clean_email'].str.len() > 20]\n","df_sample = df_sample.reset_index(drop=True)\n","\n","#installing and importing vader\n","import nltk\n","nltk.download('vader_lexicon')\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","#initializing vader\n","sia = SentimentIntensityAnalyzer()\n","\n","#get sentiment score\n","def get_sentiment_score(text):\n","    return sia.polarity_scores(text)['compound']\n","df_sample['sentiment_score'] = df_sample['clean_email'].apply(get_sentiment_score)\n","\n","#converting score to sentiment label\n","def get_sentiment_label(score):\n","    if score >= 0.05:\n","        return \"Positive\"\n","    elif score <= -0.05:\n","        return \"Negative\"\n","    else:\n","        return \"Neutral\"\n","df_sample['sentiment'] = df_sample['sentiment_score'].apply(get_sentiment_label)\n","\n","#final columns\n","df_sample = df_sample[['clean_email','sentiment']]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5NNubloIOE5","executionInfo":{"status":"ok","timestamp":1768979999518,"user_tz":-330,"elapsed":113464,"user":{"displayName":"Deshna Doshi","userId":"11987811234054001680"}},"outputId":"c0030854-402f-4222-f875-ce0209aa37ee"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","(517401, 2)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","from torch.utils.data import Dataset\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","df_sample['sentiment'] = label_encoder.fit_transform(df_sample['sentiment'])\n","\n","# Train-test split\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df_sample['clean_email'], df_sample['sentiment'], test_size=0.2, random_state=42, stratify=df_sample['sentiment']\n",")\n","\n","# -----------------------------\n","# 2. TOKENIZATION\n","# -----------------------------\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","\n","train_encodings = tokenizer(\n","    train_texts.tolist(),\n","    truncation=True,\n","    padding=True,\n","    max_length=128\n",")\n","\n","test_encodings = tokenizer(\n","    test_texts.tolist(),\n","    truncation=True,\n","    padding=True,\n","    max_length=128\n",")\n","\n","# -----------------------------\n","# 3. DATASET CLASS\n","# -----------------------------\n","class EmailDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels.tolist()\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = EmailDataset(train_encodings, train_labels)\n","test_dataset = EmailDataset(test_encodings, test_labels)\n","\n","# -----------------------------\n","# 4. LOAD MODEL\n","# -----------------------------\n","model = DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-uncased\",\n","    num_labels=3\n",")\n","\n","# -----------------------------\n","# 5. TRAINING CONFIG (LIGHT)\n","# -----------------------------\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/bert_results\",\n","    num_train_epochs=2,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_steps=100,\n","    load_best_model_at_end=False\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset\n",")\n","\n","# -----------------------------\n","# 6. TRAIN\n","# -----------------------------\n","trainer.train()\n","\n","MODEL_DIR = \"/content/drive/MyDrive/distilbert_email_model\"\n","model.save_pretrained(MODEL_DIR)\n","tokenizer.save_pretrained(MODEL_DIR)"],"metadata":{"id":"8o7SCxst3WDD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1768980522524,"user_tz":-330,"elapsed":502666,"user":{"displayName":"Deshna Doshi","userId":"11987811234054001680"}},"outputId":"de6875c8-55bb-48ba-a18e-d85782b310fc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3926' max='3926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3926/3926 07:49, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.557500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.474400</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.446800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.409200</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.453700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.381500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.370000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.346200</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.347900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.388400</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.355000</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.357100</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.311400</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.332000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.338300</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.376700</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.293200</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.362300</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.278800</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.315900</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.278900</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.281600</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.229700</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.288600</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.265600</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.254300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.211100</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.186900</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.254500</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.188000</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.289100</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.286600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.179300</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.211800</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.262100</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.206500</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.226700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/distilbert_email_model/tokenizer_config.json',\n"," '/content/drive/MyDrive/distilbert_email_model/special_tokens_map.json',\n"," '/content/drive/MyDrive/distilbert_email_model/vocab.txt',\n"," '/content/drive/MyDrive/distilbert_email_model/added_tokens.json',\n"," '/content/drive/MyDrive/distilbert_email_model/tokenizer.json')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import pandas as pd\n","import torch\n","\n","MODEL_DIR = \"/content/drive/MyDrive/distilbert_email_model\"\n","\n","print(os.path.exists(MODEL_DIR))\n","\n","from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n","\n","#MODEL_DIR = \"/content/drive/MyDrive/distilbert_email_model\"\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_DIR)\n","model = DistilBertForSequenceClassification.from_pretrained(MODEL_DIR)\n","\n","# -----------------------------\n","# 7. PREDICT ON NEW EXCEL\n","# -----------------------------\n","\n","new_df = pd.read_excel(\"/content/drive/MyDrive/sample_input_emails.xlsx\")\n","new_df[\"email_text\"] = new_df[\"email_text\"].astype(str)\n","\n","new_encodings = tokenizer(\n","    new_df[\"email_text\"].tolist(),\n","    truncation=True,\n","    padding=True,\n","    max_length=128,\n","    return_tensors=\"pt\"\n",")\n","\n","with torch.no_grad():\n","    outputs = model(**new_encodings)\n","    predictions = torch.argmax(outputs.logits, dim=1)\n","\n","id2label = {\n","    0: \"Negative\",\n","    1: \"Neutral\",\n","    2: \"Positive\"\n","}\n","\n","new_df[\"predicted_sentiment\"] = [\n","    id2label[int(i)] for i in predictions.numpy()\n","]\n","# -----------------------------\n","# 8. SAVE OUTPUT\n","# -----------------------------\n","new_df.to_excel(\"/content/drive/MyDrive/bert_predicted_sentiments.xlsx\", index=False)\n","\n","print(\"✅ DistilBERT prediction complete. Output saved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afdley5rMxzY","executionInfo":{"status":"ok","timestamp":1768988184974,"user_tz":-330,"elapsed":5640,"user":{"displayName":"Deshna Doshi","userId":"11987811234054001680"}},"outputId":"fb9487d6-c574-4c49-f9fe-e67fbaaf409d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","True\n","✅ DistilBERT prediction complete. Output saved.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bL3yt_gSCUM8","executionInfo":{"status":"ok","timestamp":1768980546448,"user_tz":-330,"elapsed":3,"user":{"displayName":"Deshna Doshi","userId":"11987811234054001680"}}},"execution_count":7,"outputs":[]}]}